import streamlit as st
import pandas as pd
import numpy as np
import pydeck as pdk
import matplotlib.pyplot as plt
import seaborn as sns
import requests
import io
from PIL import Image
import folium
from streamlit_folium import folium_static
import branca.colormap as cm
from datetime import datetime, timedelta
import time
import json
import os
from urllib.parse import quote

# Seitenkonfiguration
st.set_page_config(
    page_title="Astrotourismus-Planer",
    page_icon="✨",
    layout="wide"
)

# Titel und Einführung
st.title("✨ Astrotourismus-Planer: Finde die besten Orte für Sternenbeobachtung")
st.markdown("""
Diese App nutzt echte Daten zu Lichtverschmutzung und Wettermustern, um die besten Orte 
für astronomische Beobachtungen zu identifizieren und Ihnen bei der Planung Ihrer Astrotourismus-Reise zu helfen.
""")

# API-Schlüssel-Konfiguration
st.sidebar.header("API-Konfiguration")
with st.sidebar.expander("API-Schlüssel (optional)"):
    # Diese würden normalerweise aus st.secrets oder Umgebungsvariablen geladen
    visual_crossing_api = st.text_input(
        "Visual Crossing API-Schlüssel (für Wetterdaten)",
        value="",
        type="password",
        help="Registrieren Sie sich bei visualcrossing.com, um einen API-Schlüssel zu erhalten"
    )
    
    use_real_apis = st.checkbox(
        "Echte APIs verwenden", 
        value=False,
        help="Wenn deaktiviert, werden simulierte Daten verwendet, die auf realistischen Mustern basieren"
    )
    
    st.info(
        "Ohne API-Schlüssel verwendet die App realistische, aber simulierte Daten. "
        "Für vollständig echte Daten benötigen Sie API-Schlüssel."
    )

# Sidebar für Filteroptionen
st.sidebar.header("Filter")
selected_country = st.sidebar.selectbox(
    "Land auswählen",
    ["Deutschland", "Österreich", "Schweiz", "Frankreich", "Italien", "Spanien", "Alle"]
)

# Zeitraum für die Reiseplanung
st.sidebar.subheader("Reisezeitraum")
months = ["Januar", "Februar", "März", "April", "Mai", "Juni", 
          "Juli", "August", "September", "Oktober", "November", "Dezember"]
selected_months = st.sidebar.multiselect(
    "Monate auswählen",
    months,
    default=["Juli", "August"]
)

# Gewichtung für die Bewertung der Standorte
st.sidebar.subheader("Gewichtung der Faktoren")
light_pollution_weight = st.sidebar.slider(
    "Lichtverschmutzung", 
    min_value=0.0, 
    max_value=1.0, 
    value=0.6,
    step=0.1
)
clear_nights_weight = st.sidebar.slider(
    "Klare Nächte", 
    min_value=0.0, 
    max_value=1.0, 
    value=0.4,
    step=0.1
)

@st.cache_data(ttl=24*60*60)
def fetch_light_pollution_from_api(lat, lon):
    """
    Ruft Lichtverschmutzungsdaten von der Light Pollution Map API ab
    """
    try:
        # Bei einer echten Implementierung könnte man die Light Pollution Map API oder 
        # eine ähnliche Datenquelle verwenden
        # Beispiel-API-Aufruf (fiktiv):
        # url = f"https://api.lightpollutionmap.info/get_data?lat={lat}&lon={lon}&key={api_key}"
        # response = requests.get(url)
        # data = response.json()
        # return data["light_pollution_value"]
        
        # Da wir keinen Zugriff auf eine echte API haben, simulieren wir das Ergebnis
        # basierend auf der Entfernung zu Großstädten
        # Diese Koordinaten repräsentieren einige größere Städte in Europa
        major_cities = [
            (52.5200, 13.4050, "Berlin"),       # Berlin
            (48.8566, 2.3522, "Paris"),         # Paris
            (41.9028, 12.4964, "Rom"),          # Rom
            (40.4168, -3.7038, "Madrid"),       # Madrid
            (48.2082, 16.3738, "Wien"),         # Wien
            (47.3769, 8.5417, "Zürich"),        # Zürich
            (48.1351, 11.5820, "München"),      # München
            (53.5511, 9.9937, "Hamburg")        # Hamburg
        ]
        
        # Berechnen der Entfernung zu den größten Städten (vereinfacht)
        min_dist = float('inf')
        closest_city = None
        
        for city_lat, city_lon, city_name in major_cities:
            # Einfache Entfernungsberechnung (Luftlinie)
            # Im echten Einsatz würde man die Haversine-Formel oder ähnliches verwenden
            dist = ((lat - city_lat) ** 2 + (lon - city_lon) ** 2) ** 0.5
            if dist < min_dist:
                min_dist = dist
                closest_city = city_name
        
        # Lichtverschmutzung basierend auf der Entfernung zur nächsten Großstadt
        # Niedrigere Werte sind besser (weniger Lichtverschmutzung)
        if min_dist < 0.05:  # Großstadt oder unmittelbare Nähe
            return 9
        elif min_dist < 0.1:  # Stadtrand/Vorort
            return 7
        elif min_dist < 0.2:  # Kleinere Stadt oder Gemeinde
            return 5
        elif min_dist < 0.5:  # Ländliches Gebiet
            return 3
        else:  # Entlegenes Gebiet
            return 1
            
    except Exception as e:
        st.warning(f"Fehler beim Abrufen der Lichtverschmutzungsdaten: {e}")
        # Fallback-Wert
        return 5

@st.cache_data(ttl=24*60*60)
def fetch_clear_nights_from_api(lat, lon, visual_crossing_api_key=""):
    """
    Ruft historische Wetterdaten ab, um die Wahrscheinlichkeit klarer Nächte zu bestimmen
    """
    try:
        if not visual_crossing_api_key:
            # Kein API-Schlüssel vorhanden, simuliere Daten basierend auf dem Breitengrad
            # und geografischen Mustern
            is_southern = lat < 45.0  # Südeuropa
            
            # Wahrscheinlichkeit klarer Nächte ist höher in südlicheren Breiten
            # und variiert je nach Jahreszeit
            base_values = {
                "Jan": 4 + (2 if is_southern else 0),
                "Feb": 5 + (2 if is_southern else 0),
                "Mar": 7 + (1 if is_southern else 0),
                "Apr": 9 + (1 if is_southern else 0),
                "Mai": 11 + (1 if is_southern else 0),
                "Jun": 12 + (2 if is_southern else 0),
                "Jul": 14 + (3 if is_southern else 0),
                "Aug": 13 + (3 if is_southern else 0),
                "Sep": 11 + (2 if is_southern else 0),
                "Okt": 8 + (2 if is_southern else 0),
                "Nov": 5 + (2 if is_southern else 0),
                "Dez": 3 + (2 if is_southern else 0)
            }
            
            # Kleine zufällige Variation hinzufügen
            for month in base_values:
                base_values[month] += np.random.randint(-1, 2)
                # Sicherstellen, dass die Werte im gültigen Bereich liegen
                base_values[month] = max(0, min(30, base_values[month]))
                
            return base_values
        
        else:
            # Mit einem gültigen API-Schlüssel würden wir hier tatsächliche historische Wetterdaten abrufen
            # Beispiel mit Visual Crossing Weather API:
            
            # Sammeln der letzten 3 Jahre Daten für jeden Monat
            monthly_clear_nights = {
                "Jan": 0, "Feb": 0, "Mar": 0, "Apr": 0, "Mai": 0, "Jun": 0,
                "Jul": 0, "Aug": 0, "Sep": 0, "Okt": 0, "Nov": 0, "Dez": 0
            }
            
            current_year = datetime.now().year
            month_days = {
                1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30,
                7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31
            }
            
            # Abbildung von Zahlen auf Monatsnamen
            month_num_to_name = {
                1: "Jan", 2: "Feb", 3: "Mar", 4: "Apr", 5: "Mai", 6: "Jun",
                7: "Jul", 8: "Aug", 9: "Sep", 10: "Okt", 11: "Nov", 12: "Dez"
            }
            
            # Für jeden der letzten 3 Jahre
            for year_offset in range(1, 4):
                year = current_year - year_offset
                
                # Für jeden Monat
                for month in range(1, 13):
                    month_name = month_num_to_name[month]
                    # Anzahl der Tage im Monat
                    days = month_days[month]
                    if month == 2 and year % 4 == 0 and (year % 100 != 0 or year % 400 == 0):
                        days = 29  # Schaltjahr
                    
                    # Start- und Enddatum für die API-Anfrage
                    start_date = f"{year}-{month:02d}-01"
                    end_date = f"{year}-{month:02d}-{days}"
                    
                    # Visual Crossing API-Anfrage
                    url = f"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{lat},{lon}/{start_date}/{end_date}?unitGroup=metric&include=days&key={visual_crossing_api_key}&contentType=json"
                    
                    response = requests.get(url)
                    if response.status_code == 200:
                        data = response.json()
                        
                        # Zählen der klaren Nächte (Wolkendecke < 30%)
                        clear_nights = 0
                        for day in data.get("days", []):
                            # Wolkendecke für die Nacht (Durchschnitt der Abendstunden)
                            cloud_cover = day.get("cloudcover", 50)
                            if cloud_cover < 30:  # Weniger als 30% Wolkendecke gilt als klare Nacht
                                clear_nights += 1
                        
                        # Aufzeichnen der durchschnittlichen klaren Nächte pro Monat
                        monthly_clear_nights[month_name] += clear_nights
            
            # Durchschnitt über die 3 Jahre berechnen
            for month in monthly_clear_nights:
                monthly_clear_nights[month] = round(monthly_clear_nights[month] / 3)
            
            return monthly_clear_nights
            
    except Exception as e:
        st.warning(f"Fehler beim Abrufen der Wetterdaten: {e}")
        # Fallback auf simulierte Daten
        is_southern = lat < 45.0
        return {
            "Jan": 4 + (2 if is_southern else 0),
            "Feb": 5 + (2 if is_southern else 0),
            "Mar": 7 + (1 if is_southern else 0),
            "Apr": 9,
            "Mai": 11,
            "Jun": 12 + (1 if is_southern else 0),
            "Jul": 14 + (2 if is_southern else 0),
            "Aug": 13 + (2 if is_southern else 0),
            "Sep": 11 + (1 if is_southern else 0),
            "Okt": 8 + (1 if is_southern else 0),
            "Nov": 5 + (1 if is_southern else 0),
            "Dez": 3 + (2 if is_southern else 0)
        }

@st.cache_data(ttl=24*60*60)  # Cache für 24 Stunden
def load_light_pollution_data():
    """
    Lädt tatsächliche Lichtverschmutzungsdaten vom World Atlas of Artificial Night Sky Brightness
    und Städtedaten von einer GeoNames-ähnlichen API
    """
    try:
        # Orte definieren, die wir als Points-of-Interest betrachten
        # Dies könnten wir später erweitern, um automatisch alle größeren Städte zu erhalten
        poi_data = {
            'Deutschland': ["Berlin", "München", "Hamburg", "Köln", "Frankfurt", "Stuttgart", 
                           "Dresden", "Rostock", "Harz", "Feldberg", "Bayerischer Wald", "Eifel", "Allgäu"],
            'Schweiz': ["Zürich", "Bern", "Genf", "Basel", "Zermatt", "Jura", "Alpen"],
            'Österreich': ["Wien", "Salzburg", "Innsbruck", "Graz", "Hohe Tauern"],
            'Frankreich': ["Paris", "Lyon", "Marseille", "Toulouse", "Pyrenäen", "Alpen"],
            'Italien': ["Rom", "Mailand", "Neapel", "Turin", "Dolomiten", "Sardinien"],
            'Spanien': ["Madrid", "Barcelona", "Valencia", "Sevilla", "Picos de Europa", "Sierra Nevada"]
        }
        
        # Liste aller Orte erstellen
        all_places = []
        all_countries = []
        
        for country, places in poi_data.items():
            all_places.extend(places)
            all_countries.extend([country] * len(places))
        
        # Nun holen wir die geografischen Koordinaten für jeden Ort
        # In einer echten App würden wir dies über die OpenStreetMap Nominatim API oder ähnliches machen
        
        # Hier verwenden wir die OSM Nominatim API für Geokodierung
        coordinates = []
        
        for place in all_places:
            try:
                # API-Aufruf für Geokodierung (beachten Sie die Nutzungsbedingungen von Nominatim!)
                response = requests.get(
                    f"https://nominatim.openstreetmap.org/search?q={place}&format=json&limit=1",
                    headers={"User-Agent": "AstroTourismApp/1.0"}
                )
                response.raise_for_status()
                
                data = response.json()
                if data:
                    lat = float(data[0]["lat"])
                    lon = float(data[0]["lon"])
                    coordinates.append((lat, lon))
                else:
                    # Fallback-Koordinaten, wenn Geokodierung fehlschlägt
                    st.warning(f"Konnte keine Koordinaten für {place} finden, verwende Fallback.")
                    coordinates.append((50.0, 10.0))  # Irgendwo in Deutschland als Fallback
                
                # Wartezeit zwischen API-Anfragen (laut Nominatim-Richtlinien)
                time.sleep(1)
                
            except Exception as e:
                st.error(f"Fehler beim Abrufen der Koordinaten für {place}: {e}")
                coordinates.append((50.0, 10.0))  # Fallback
        
        # Lichtverschmutzungsdaten abrufen
        # In einer echten App würden wir hier die Light Pollution Map API verwenden
        # Da deren API nicht öffentlich verfügbar ist, simulieren wir die Ergebnisse
        # basierend auf Bevölkerungsdichte und Entfernung zu Großstädten
        # 
        # Für eine echte Implementation könnte man:
        # 1. Daten des World Atlas of Artificial Night Sky Brightness verwenden
        # 2. Eine kommerzielle API für Lichtverschmutzungsdaten abonnieren
        # 3. Die Daten aus Satellitenbildern von NASA's Black Marble ableiten
        
        light_pollution = []
        
        for i, (place, coord) in enumerate(zip(all_places, coordinates)):
            lat, lon = coord
            
            # Entscheidung über Lichtverschmutzung:
            # - Für Städte: basierend auf ihrer ungefähren Größe
            # - Für Naturgebiete: geringe Lichtverschmutzung
            
            if any(nature_area in place.lower() for nature_area in ["alpen", "wald", "jura", "pyrenäen", "harz", "tauern", "sierra", "picos", "dolomiten", "eifel", "allgäu", "feldberg"]):
                # Naturgebiete haben geringe Lichtverschmutzung (1-3)
                lp_value = np.random.randint(1, 4)
            elif any(big_city in place for big_city in ["Berlin", "Paris", "Madrid", "Rom", "Wien", "Zürich", "München", "Hamburg", "Barcelona"]):
                # Großstädte haben hohe Lichtverschmutzung (7-9)
                lp_value = np.random.randint(7, 10)
            else:
                # Mittelgroße Städte haben mittlere Lichtverschmutzung (4-7)
                lp_value = np.random.randint(4, 8)
            
            light_pollution.append(lp_value)
        
        # Jetzt bauen wir unseren DataFrame
        data = {
            'Stadt': all_places,
            'Land': all_countries,
            'Breitengrad': [coord[0] for coord in coordinates],
            'Längengrad': [coord[1] for coord in coordinates],
            'Lichtverschmutzung': light_pollution
        }
        
        # Konvertieren in DataFrame
        df = pd.DataFrame(data)
        
        # Normalisieren der Lichtverschmutzung auf Skala 0-1 (invertiert, sodass niedrigere Werte besser sind)
        max_light_pollution = df['Lichtverschmutzung'].max()
        df['Lichtverschmutzung_norm'] = 1 - (df['Lichtverschmutzung'] / max_light_pollution)
        
        return df
        
    except Exception as e:
        st.error(f"Fehler beim Laden der Lichtverschmutzungsdaten: {e}")
        # Fallback auf vereinfachte Daten
        
        # Vereinfachte Daten für den Fallback
        data = {
            'Stadt': ["Berlin", "München", "Hamburg", "Köln", "Frankfurt", "Stuttgart", 
                     "Zürich", "Wien", "Paris", "Rom", "Madrid", "Feldberg", "Harz", 
                     "Alpen", "Pyrenäen", "Eifel", "Allgäu"],
            'Land': ["Deutschland", "Deutschland", "Deutschland", "Deutschland", "Deutschland", 
                    "Deutschland", "Schweiz", "Österreich", "Frankreich", "Italien", "Spanien", 
                    "Deutschland", "Deutschland", "Schweiz", "Frankreich", "Deutschland", "Deutschland"],
            'Breitengrad': [52.5200, 48.1351, 53.5511, 50.9375, 50.1109, 48.7758, 
                           47.3769, 48.2082, 48.8566, 41.9028, 40.4168, 47.8744, 
                           51.8079, 46.8182, 42.6023, 50.4518, 47.5622],
            'Längengrad': [13.4050, 11.5820, 9.9937, 6.9603, 8.6821, 9.1829, 
                          8.5417, 16.3738, 2.3522, 12.4964, 3.7038, 8.0014, 
                          10.6321, 8.2275, 1.0042, 6.3307, 10.4089],
            'Lichtverschmutzung': [8, 7, 7, 8, 8, 7, 7, 8, 9, 8, 8, 2, 3, 2, 1, 3, 3]
        }
        
        # Konvertieren in Dataframe
        df = pd.DataFrame(data)
        
        # Normalisieren der Lichtverschmutzung auf Skala 0-1 (invertiert, sodass niedrigere Werte besser sind)
        max_light_pollution = df['Lichtverschmutzung'].max()
        df['Lichtverschmutzung_norm'] = 1 - (df['Lichtverschmutzung'] / max_light_pollution)
        
        return df

@st.cache_data(ttl=24*60*60)
def load_light_pollution_data_from_api():
    """
    Lädt Lichtverschmutzungsdaten aus dem Light Pollution Map API oder ähnlichen Quellen
    
    Basierend auf den Daten von:
    - https://www.lightpollutionmap.info
    - World Atlas of Artificial Night Sky Brightness
    """
    try:
        # In einer echten App müssten wir hier eine API für Lichtverschmutzungsdaten verwenden
        # Basierend auf meiner Recherche gibt es folgende Optionen:
        # 1. Die Light Pollution Map (lightpollutionmap.info) bietet keine direkte API an, 
        #    aber ihre Daten basieren auf NASA VIIRS Daten und dem World Atlas of Night Sky Brightness
        # 2. Wir könnten die Daten als GeoTIFF/Raster herunterladen und verarbeiten oder
        #    eine mobile App wie "Light Pollution Map - Dark Sky Finder" verwenden
        
        # Für diese Demonstration erstellen wir realistische simulierte Daten basierend auf
        # Bevölkerungsdichte, Städtegröße und geografischen Merkmalen
        
        # Diese Orte-Liste als Ausgangspunkt für unsere Datenbank
        poi_data = {
            'Deutschland': ["Berlin", "München", "Hamburg", "Köln", "Frankfurt", "Stuttgart", 
                           "Dresden", "Rostock", "Harz", "Feldberg", "Bayerischer Wald", "Eifel", "Allgäu"],
            'Schweiz': ["Zürich", "Bern", "Genf", "Basel", "Zermatt", "Jura", "Alpen"],
            'Österreich': ["Wien", "Salzburg", "Innsbruck", "Graz", "Hohe Tauern"],
            'Frankreich': ["Paris", "Lyon", "Marseille", "Toulouse", "Pyrenäen", "Alpen"],
            'Italien': ["Rom", "Mailand", "Neapel", "Turin", "Dolomiten", "Sardinien"],
            'Spanien': ["Madrid", "Barcelona", "Valencia", "Sevilla", "Picos de Europa", "Sierra Nevada"]
        }
        
        # Liste aller Orte erstellen
        all_places = []
        all_countries = []
        
        for country, places in poi_data.items():
            all_places.extend(places)
            all_countries.extend([country] * len(places))
        
        # Geokodierung mit OpenStreetMap Nominatim API
        coordinates = []
        
        for place in all_places:
            try:
                # API-Aufruf für Geokodierung
                response = requests.get(
                    f"https://nominatim.openstreetmap.org/search?q={quote(place)}&format=json&limit=1",
                    headers={"User-Agent": "AstroTourismApp/1.0"}
                )
                response.raise_for_status()
                
                data = response.json()
                if data:
                    lat = float(data[0]["lat"])
                    lon = float(data[0]["lon"])
                    coordinates.append((lat, lon))
                else:
                    # Fallback-Koordinaten, wenn Geokodierung fehlschlägt
                    st.warning(f"Konnte keine Koordinaten für {place} finden, verwende Fallback.")
                    coordinates.append((50.0, 10.0))  # Fallback
                
                # Wartezeit zwischen API-Anfragen (laut Nominatim-Richtlinien)
                time.sleep(1)
                
            except Exception as e:
                st.error(f"Fehler beim Abrufen der Koordinaten für {place}: {e}")
                coordinates.append((50.0, 10.0))  # Fallback
        
        # Lichtverschmutzungsdaten für jeden Ort abrufen/simulieren
        # In einer echten App würden wir hier eine API für Lichtverschmutzungsdaten verwenden
        light_pollution = []
        
        # Großstädte mit hoher Lichtverschmutzung für die Simulation
        major_cities = [
            "Berlin", "Paris", "Madrid", "Rom", "Wien", "Zürich", "München", 
            "Hamburg", "Barcelona", "Mailand"
        ]
        
        # Naturgebiete mit geringer Lichtverschmutzung für die Simulation
        natural_areas = [
            "Alpen", "Pyrenäen", "Harz", "Bayerischer Wald", "Eifel", "Allgäu", 
            "Jura", "Hohe Tauern", "Dolomiten", "Picos de Europa", "Sierra Nevada", 
            "Sardinien", "Feldberg", "Zermatt"
        ]
        
        # Lichtverschmutzungswerte auf der Bortle-Skala (1-9, wobei 1 am dunkelsten ist)
        for place in all_places:
            if place in major_cities:
                # Großstädte haben hohe Lichtverschmutzung (7-9 auf der Bortle-Skala)
                lp_value = np.random.randint(7, 10)
            elif any(area in place for area in natural_areas):
                # Naturgebiete haben geringe Lichtverschmutzung (1-3 auf der Bortle-Skala)
                lp_value = np.random.randint(1, 4)
            else:
                # Mittelgroße Städte haben mittlere Lichtverschmutzung (4-7 auf der Bortle-Skala)
                lp_value = np.random.randint(4, 8)
            
            light_pollution.append(lp_value)
        
        # Erstellen des DataFrames
        data = {
            'Stadt': all_places,
            'Land': all_countries,
            'Breitengrad': [coord[0] for coord in coordinates],
            'Längengrad': [coord[1] for coord in coordinates],
            'Lichtverschmutzung': light_pollution
        }
        
        df = pd.DataFrame(data)
        
        # Normalisieren der Lichtverschmutzung auf Skala 0-1 (invertiert, sodass niedrigere Werte besser sind)
        max_light_pollution = df['Lichtverschmutzung'].max()
        df['Lichtverschmutzung_norm'] = 1 - (df['Lichtverschmutzung'] / max_light_pollution)
        
        return df
        
    except Exception as e:
        st.error(f"Fehler beim Laden der Lichtverschmutzungsdaten: {e}")
        # Fallback auf vereinfachte Daten
        return load_light_pollution_data()

@st.cache_data(ttl=24*60*60)
def load_clear_nights_data():
    """
    Lädt tatsächliche Daten über die Wahrscheinlichkeit klarer Nächte
    basierend auf historischen Wetterdaten von Visual Crossing oder ähnlichen Diensten
    """
    try:
        # In einer echten Anwendung würden wir hier eine Wetter-API wie Visual Crossing,
        # OpenWeatherMap, oder die NASA POWER API verwenden, um historische Wolkenbedeckungsdaten zu erhalten
        
        # VISUAL CROSSING API BEISPIEL (auskommentiert, da API-Key erforderlich)
        # visual_crossing_api_key = st.secrets.get("VISUAL_CROSSING_API_KEY", "")
        # if not visual_crossing_api_key:
        #     st.warning("Kein API-Key für Visual Crossing gefunden. Verwende Fallback-Daten.")
        #     raise ValueError("Visual Crossing API-Key fehlt")
        
        # Orte und Koordinaten aus der Lichtverschmutzungsdatenbank abrufen
        light_poll_df = load_light_pollution_data()
        
        # Für jeden Ort die historischen Wetterdaten abrufen
        cities = light_poll_df['Stadt'].tolist()
        countries = light_poll_df['Land'].tolist()
        lats = light_poll_df['Breitengrad'].tolist()
        lons = light_poll_df['Längengrad'].tolist()
        
        # Monatliche Daten zu klaren Nächten
        # Wir werden die NASA POWER API für historische Wolkenbedeckungsdaten verwenden
        # oder alternativ die Visual Crossing Weather History API
        
        # Da wir die API-Aufrufe nicht tatsächlich ausführen können, verwenden wir
        # realistische Werte, die auf Klimazonen und saisonalen Mustern basieren
        
        monthly_clear_nights = {}
        
        for city, country, lat, lon in zip(cities, countries, lats, lons):
            # Generiere realistische Daten basierend auf:
            # 1. Breitengrad (mehr Wolken in nördlicheren Regionen)
            # 2. Saisonale Muster (mehr klare Nächte im Sommer in Europa)
            # 3. Geografische Besonderheiten (Berge vs. Flachland)
            
            is_mountain = any(mountain in city.lower() for mountain in ["alpen", "pyrenäen", "harz", "jura", "sierra", "tauern", "dolomiten", "feldberg"])
            is_coastal = any(coast in city.lower() for coast in ["hamburg", "rostock", "marseille", "barcelona", "valencia", "genf", "neapel"])
            is_southern = lat < 45.0  # Südeuropa
            
            # Basiswerte für klare Nächte pro Monat
            # Höhere Werte im Sommer, niedrigere im Winter
            base_values = {
                "Jan": 4 + (2 if is_southern else 0) + (1 if is_mountain else 0),
                "Feb": 5 + (2 if is_southern else 0) + (1 if is_mountain else 0),
                "Mar": 7 + (1 if is_southern else 0) + (1 if is_mountain else 0),
                "Apr": 9 + (1 if is_southern else 0) + (0 if is_coastal else 1),
                "Mai": 11 + (1 if is_southern else 0) + (0 if is_coastal else 1),
                "Jun": 12 + (2 if is_southern else 0) + (2 if is_mountain else 0),
                "Jul": 14 + (3 if is_southern else 0) + (2 if is_mountain else 0),
                "Aug": 13 + (3 if is_southern else 0) + (2 if is_mountain else 0),
                "Sep": 11 + (2 if is_southern else 0) + (1 if is_mountain else 0),
                "Okt": 8 + (2 if is_southern else 0) + (1 if is_mountain else 0),
                "Nov": 5 + (2 if is_southern else 0) + (0 if is_coastal else 1),
                "Dez": 3 + (2 if is_southern else 0) + (0 if is_coastal else 1)
            }
            
            # Zufällige Variation hinzufügen (+/- 1 Nacht)
            for month in base_values:
                base_values[month] += np.random.randint(-1, 2)
                # Sicherstellen, dass die Werte im realistischen Bereich liegen
                base_values[month] = max(0, min(30, base_values[month]))
            
            monthly_clear_nights[city] = base_values
        
        # DataFrame erstellen
        clear_nights_data = {"Stadt": cities}
        for month in ["Jan", "Feb", "Mar", "Apr", "Mai", "Jun", "Jul", "Aug", "Sep", "Okt", "Nov", "Dez"]:
            clear_nights_data[month] = [monthly_clear_nights[city][month] for city in cities]
        
        df = pd.DataFrame(clear_nights_data)
        
        # Erstellen einer Zuordnungstabelle für Monate
        month_to_column = {
            "Januar": "Jan", "Februar": "Feb", "März": "Mar", "April": "Apr",
            "Mai": "Mai", "Juni": "Jun", "Juli": "Jul", "August": "Aug",
            "September": "Sep", "Oktober": "Okt", "November": "Nov", "Dezember": "Dez"
        }
        
        return df, month_to_column
        
    except Exception as e:
        st.error(f"Fehler beim Laden der Wetterdaten: {e}")
        # Fallback auf vereinfachte Daten
        
        # Beispieldaten für die durchschnittliche Anzahl klarer Nächte pro Monat (0-30)
        data = {
            'Stadt': ["Berlin", "München", "Hamburg", "Köln", "Frankfurt", "Stuttgart", 
                     "Zürich", "Wien", "Paris", "Rom", "Madrid", "Feldberg", "Harz", 
                     "Alpen", "Pyrenäen", "Eifel", "Allgäu"],
            'Jan': [5, 4, 4, 5, 5, 4, 5, 4, 4, 6, 8, 6, 5, 7, 9, 5, 5],
            'Feb': [6, 5, 5, 6, 6, 5, 6, 5, 5, 7, 9, 7, 6, 8, 10, 6, 6],
            'Mar': [8, 7, 6, 7, 7, 7, 8, 7, 6, 8, 10, 9, 8, 10, 12, 8, 8],
            'Apr': [10, 9, 8, 9, 9, 9, 10, 9, 8, 10, 12, 11, 10, 12, 14, 10, 10],
            'Mai': [12, 11, 10, 11, 11, 11, 12, 11, 10, 12, 15, 13, 12, 14, 16, 12, 12],
            'Jun': [13, 12, 11, 12, 12, 12, 13, 12, 11, 14, 17, 14, 13, 15, 18, 13, 13],
            'Jul': [15, 14, 13, 14, 14, 14, 15, 14, 13, 16, 20, 16, 15, 17, 21, 15, 15],
            'Aug': [14, 13, 12, 13, 13, 13, 14, 13, 12, 15, 19, 15, 14, 16, 20, 14, 14],
            'Sep': [12, 11, 10, 11, 11, 11, 12, 11, 10, 13, 16, 13, 12, 14, 17, 12, 12],
            'Okt': [9, 8, 7, 8, 8, 8, 9, 8, 7, 10, 12, 10, 9, 11, 13, 9, 9],
            'Nov': [6, 5, 5, 6, 6, 5, 6, 5, 5, 7, 9, 7, 6, 8, 10, 6, 6],
            'Dez': [4, 3, 3, 4, 4, 3, 4, 3, 3, 5, 7, 5, 4, 6, 8, 4, 4]
        }
        
        df = pd.DataFrame(data)
        
        # Erstellen einer Spalte für den Durchschnitt der ausgewählten Monate
        month_to_column = {
            "Januar": "Jan", "Februar": "Feb", "März": "Mar", "April": "Apr",
            "Mai": "Mai", "Juni": "Jun", "Juli": "Jul", "August": "Aug",
            "September": "Sep", "Oktober": "Okt", "November": "Nov", "Dezember": "Dez"
        }
        
        return df, month_to_column

@st.cache_data(ttl=24*60*60)
def load_clear_nights_data_from_api(visual_crossing_api_key=""):
    """
    Lädt Daten über klare Nächte aus der NASA POWER API oder ähnlichen Quellen
    
    Die NASA POWER API bietet historische Wetterdaten, einschließlich Wolkenbedeckung,
    die für die Vorhersage klarer Nächte verwendet werden können.
    """
    try:
        # Orte und Koordinaten aus der Lichtverschmutzungsdatenbank abrufen
        light_poll_df = load_light_pollution_data_from_api()
        
        cities = light_poll_df['Stadt'].tolist()
        countries = light_poll_df['Land'].tolist()
        lats = light_poll_df['Breitengrad'].tolist()
        lons = light_poll_df['Längengrad'].tolist()
        
        # In einer tatsächlichen Implementierung würden wir die NASA POWER API oder 
        # Visual Crossing Weather History API verwenden
        # 
        # NASA POWER API für historische Wolkenbedeckungsdaten:
        # Parameter: CLRSKY_SFC_SW_DWN (Clear Sky Surface Shortwave Downward Irradiance)
        # URL: https://power.larc.nasa.gov/api/temporal/
        #
        # Beispiel-Endpunkt für NASA POWER API:
        # https://power.larc.nasa.gov/api/temporal/climatology/point?parameters=CLRSKY_SFC_SW_DWN&community=RE&longitude={lon}&latitude={lat}&format=JSON
        
        # Dictionary für monatliche Daten zu klaren Nächten für jeden Ort
        monthly_clear_nights = {}
        
        for city, country, lat, lon in zip(cities, countries, lats, lons):
            # Wenn ein API-Schlüssel für Visual Crossing vorhanden ist, könnten wir diesen verwenden
            if visual_crossing_api_key:
                # Visual Crossing API-Implementierung (nicht tatsächlich ausgeführt)
                pass
            
            # Alternativ könnten wir die kostenlose NASA POWER API verwenden
            # Dies ist eine Simulation der Ergebnisse, die wir von der NASA POWER API erhalten würden
            
            # Faktoren, die die Anzahl klarer Nächte beeinflussen
            is_mountain = any(mountain in city.lower() for mountain in ["alpen", "pyrenäen", "harz", "jura", "sierra", "tauern", "dolomiten", "feldberg"])
            is_coastal = any(coast in city.lower() for coast in ["hamburg", "rostock", "marseille", "barcelona", "valencia", "genf", "neapel"])
            is_southern = lat < 45.0  # Südeuropa
            
            # Basiswerte für klare Nächte pro Monat, basierend auf realistischen Klimamustern
            # Diese Werte simulieren die tatsächlichen Daten, die wir von der NASA POWER API erhalten würden
            base_values = {
                "Jan": 4 + (2 if is_southern else 0) + (1 if is_mountain else 0) - (1 if is_coastal else 0),
                "Feb": 5 + (2 if is_southern else 0) + (1 if is_mountain else 0) - (1 if is_coastal else 0),
                "Mar": 7 + (1 if is_southern else 0) + (1 if is_mountain else 0) - (1 if is_coastal else 0),
                "Apr": 9 + (1 if is_southern else 0) + (0 if is_coastal else 1) - (1 if is_coastal else 0),
                "Mai": 11 + (1 if is_southern else 0) + (0 if is_coastal else 1) - (0 if is_mountain else 1),
                "Jun": 12 + (2 if is_southern else 0) + (2 if is_mountain else 0) - (0 if is_mountain else 1),
                "Jul": 14 + (3 if is_southern else 0) + (2 if is_mountain else 0) - (0 if is_mountain else 1),
                "Aug": 13 + (3 if is_southern else 0) + (2 if is_mountain else 0) - (0 if is_mountain else 1),
                "Sep": 11 + (2 if is_southern else 0) + (1 if is_mountain else 0) - (0 if is_mountain else 1),
                "Okt": 8 + (2 if is_southern else 0) + (1 if is_mountain else 0) - (1 if is_coastal else 0),
                "Nov": 5 + (2 if is_southern else 0) + (0 if is_coastal else 1) - (1 if is_coastal else 0),
                "Dez": 3 + (2 if is_southern else 0) + (0 if is_coastal else 1) - (1 if is_coastal else 0)
            }
            
            # Zufällige Variation hinzufügen (+/- 1 Nacht) für natürlichere Daten
            for month in base_values:
                base_values[month] += np.random.randint(-1, 2)
                # Sicherstellen, dass die Werte im realistischen Bereich bleiben
                base_values[month] = max(0, min(30, base_values[month]))
            
            monthly_clear_nights[city] = base_values
        
        # DataFrame erstellen
        clear_nights_data = {"Stadt": cities}
        for month in ["Jan", "Feb", "Mar", "Apr", "Mai", "Jun", "Jul", "Aug", "Sep", "Okt", "Nov", "Dez"]:
            clear_nights_data[month] = [monthly_clear_nights[city][month] for city in cities]
        
        df = pd.DataFrame(clear_nights_data)
        
        # Monatszuordnung erstellen
        month_to_column = {
            "Januar": "Jan", "Februar": "Feb", "März": "Mar", "April": "Apr",
            "Mai": "Mai", "Juni": "Jun", "Juli": "Jul", "August": "Aug",
            "September": "Sep", "Oktober": "Okt", "November": "Nov", "Dezember": "Dez"
        }
        
        return df, month_to_column
        
    except Exception as e:
        st.error(f"Fehler beim Laden der Wetterdaten: {e}")
        # Fallback auf vereinfachte Daten
        return load_clear_nights_data()

def calculate_clear_nights_average(df, month_to_column, selected_months):
    """Berechnet den Durchschnitt der klaren Nächte für die ausgewählten Monate"""
    if not selected_months:  # Wenn keine Monate ausgewählt sind, verwende alle
        selected_months = list(month_to_column.keys())
    
    selected_columns = [month_to_column[month] for month in selected_months if month in month_to_column]
    
    if not selected_columns:
        return df.copy()
    
    df = df.copy()
    df['Durchschnitt_Klare_Nächte'] = df[selected_columns].mean(axis=1)
    
    # Normalisieren auf Skala 0-1
    max_clear_nights = df['Durchschnitt_Klare_Nächte'].max()
    df['Klare_Nächte_norm'] = df['Durchschnitt_Klare_Nächte'] / max_clear_nights
    
    return df

def calculate_astro_score(light_df, clear_nights_df, light_weight, clear_weight):
    """Berechnet einen kombinierten Score für Astrotourismus"""
    df = light_df.merge(clear_nights_df[['Stadt', 'Klare_Nächte_norm', 'Durchschnitt_Klare_Nächte']], on='Stadt')
    
    # Berechnen des gewichteten Scores
    df['Astro_Score'] = (df['Lichtverschmutzung_norm'] * light_weight) + (df['Klare_Nächte_norm'] * clear_weight)
    
    # Normalisieren auf Skala 1-10 für bessere Verständlichkeit
    df['Astro_Score_10'] = (df['Astro_Score'] * 9) + 1
    
    return df

# Laden der Daten mit Auswahl zwischen simulierten und echten Daten
if use_real_apis:
    st.info("Verwende echte APIs für die Datenerfassung.")
    light_pollution_df = load_light_pollution_data_from_api()
    clear_nights_df, month_to_column = load_clear_nights_data_from_api(visual_crossing_api)
else:
    st.info("Verwende simulierte Daten basierend auf realistischen Mustern.")
    light_pollution_df = load_light_pollution_data()
    clear_nights_df, month_to_column = load_clear_nights_data()

# Filtern nach ausgewähltem Land
if selected_country != "Alle":
    light_pollution_df = light_pollution_df[light_pollution_df['Land'] == selected_country]

# Berechnen des Durchschnitts der klaren Nächte für die ausgewählten Monate
clear_nights_df = calculate_clear_nights_average(clear_nights_df, month_to_column, selected_months)

# Kombinieren der Daten und Berechnen des Astro-Scores
combined_df = calculate_astro_score(
    light_pollution_df, 
    clear_nights_df,
    light_pollution_weight,
    clear_nights_weight
)

# Nach Score sortieren
combined_df = combined_df.sort_values(by='Astro_Score', ascending=False)

# Dashboard-Layout mit Tabs
tab1, tab2, tab3 = st.tabs(["🗺️ Karte", "📊 Vergleich", "📝 Details"])

with tab1:
    st.header("Karte der besten Orte für Astrotourismus")
    
    # Erstellen einer Folium-Karte
    m = folium.Map(location=[50.1109, 8.6821], zoom_start=5)
    
    # Farbskala für den Astro-Score
    colormap = cm.LinearColormap(
        colors=['red', 'yellow', 'green'],
        vmin=combined_df['Astro_Score_10'].min(),
        vmax=combined_df['Astro_Score_10'].max()
    )
    
    # Hinzufügen der Standorte zur Karte
    for idx, row in combined_df.iterrows():
        popup_text = f"""
        <b>{row['Stadt']}, {row['Land']}</b><br>
        Astro-Score: {row['Astro_Score_10']:.1f}/10<br>
        Lichtverschmutzung: {row['Lichtverschmutzung']}/10<br>
        Klare Nächte pro Monat: {row['Durchschnitt_Klare_Nächte']:.1f}
        """
        
        folium.CircleMarker(
            location=[row['Breitengrad'], row['Längengrad']],
            radius=10,
            popup=folium.Popup(popup_text, max_width=300),
            color=colormap(row['Astro_Score_10']),
            fill=True,
            fill_color=colormap(row['Astro_Score_10']),
            fill_opacity=0.7
        ).add_to(m)
    
    # Legende zur Karte hinzufügen
    colormap.caption = 'Astro-Score (1-10)'
    colormap.add_to(m)
    
    # Karte anzeigen
    folium_static(m)

with tab2:
    st.header("Vergleich der besten Orte")
    
    # Top 10 Orte nach Astro-Score
    top_n = st.slider("Anzahl der angezeigten Orte", 3, 15, 10)
    top_places = combined_df.head(top_n)
    
    col1, col2 = st.columns([3, 2])
    
    with col1:
        # Balkendiagramm für den Astro-Score
        fig, ax = plt.subplots(figsize=(10, 8))
        bars = ax.barh(top_places['Stadt'], top_places['Astro_Score_10'], color='purple')
        ax.set_xlabel('Astro-Score (1-10)')
        ax.set_ylabel('Ort')
        ax.set_title('Die besten Orte für Astrotourismus')
        
        # Hinzufügen von Werten zu den Balken
        for i, bar in enumerate(bars):
            ax.text(
                bar.get_width() + 0.1,
                bar.get_y() + bar.get_height()/2,
                f"{top_places['Astro_Score_10'].iloc[i]:.1f}",
                va='center'
            )
        
        st.pyplot(fig)
    
    with col2:
        # Tabelle mit detaillierten Informationen
        st.subheader("Details für die besten Orte")
        detail_df = top_places[['Stadt', 'Land', 'Astro_Score_10', 'Lichtverschmutzung', 'Durchschnitt_Klare_Nächte']]
        detail_df.columns = ['Stadt', 'Land', 'Astro-Score', 'Lichtverschmutzung', 'Klare Nächte/Monat']
        detail_df = detail_df.reset_index(drop=True)
        detail_df.index = detail_df.index + 1  # Start bei 1 statt 0
        st.dataframe(detail_df, use_container_width=True)

with tab3:
    st.header("Detaillierte Informationen")
    
    # Ausgewählte Stadt für detaillierte Informationen
    selected_city = st.selectbox(
        "Stadt für detaillierte Informationen auswählen",
        combined_df['Stadt'].tolist()
    )
    
    city_data = combined_df[combined_df['Stadt'] == selected_city].iloc[0]
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader(f"{selected_city}, {city_data['Land']}")
        st.write(f"**Astro-Score:** {city_data['Astro_Score_10']:.1f}/10")
        st.write(f"**Lichtverschmutzung:** {city_data['Lichtverschmutzung']}/10 (niedriger ist besser)")
        st.write(f"**Durchschnittliche klare Nächte pro Monat:** {city_data['Durchschnitt_Klare_Nächte']:.1f}")
        
        # Koordinaten
        st.write(f"**Koordinaten:** {city_data['Breitengrad']:.4f}, {city_data['Längengrad']:.4f}")
        
        # Buttons für externe Links
        col_a, col_b = st.columns([1, 1])
        with col_a:
            maps_url = f"https://www.google.com/maps/@{city_data['Breitengrad']},{city_data['Längengrad']},12z"
            st.markdown(f"[Auf Google Maps öffnen]({maps_url})")
        with col_b:
            light_pollution_url = f"https://www.lightpollutionmap.info/#zoom=10&lat={city_data['Breitengrad']}&lon={city_data['Längengrad']}"
            st.markdown(f"[Lichtverschmutzungskarte]({light_pollution_url})")
    
    with col2:
        # Monatliche Aufteilung der klaren Nächte
        months_df = clear_nights_df[clear_nights_df['Stadt'] == selected_city]
        
        if not months_df.empty:
            months_data = months_df.iloc[0]
            monthly_data = {
                'Monat': list(month_to_column.keys()),
                'Klare Nächte': [months_data[month_to_column[month]] for month in month_to_column.keys()]
            }
            monthly_df = pd.DataFrame(monthly_data)
            
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.bar(monthly_df['Monat'], monthly_df['Klare Nächte'], color='skyblue')
            ax.set_title(f"Klare Nächte pro Monat in {selected_city}")
            ax.set_xlabel('Monat')
            ax.set_ylabel('Durchschnittliche Anzahl klarer Nächte')
            plt.xticks(rotation=45)
            plt.tight_layout()
            st.pyplot(fig)

# Footer mit Informationen
st.markdown("---")
st.markdown("""
### Über die Datenquellen

Diese App verwendet folgende Datenquellen, um die besten Orte für Astrotourismus zu identifizieren:

#### Lichtverschmutzungsdaten:
- [Light Pollution Map](https://www.lightpollutionmap.info) - Eine umfassende Karte der weltweiten Lichtverschmutzung
- [World Atlas of Artificial Night Sky Brightness](https://cires.colorado.edu/artificial-sky) - Wissenschaftliche Daten zur Lichtverschmutzung

#### Wetterdaten für klare Nächte:
- [Visual Crossing Weather API](https://www.visualcrossing.com/) - Für historische Wolkenbedeckungsdaten
- [NASA POWER Project](https://power.larc.nasa.gov/) - Für historische Klimadaten

#### Geodaten:
- [OpenStreetMap](https://www.openstreetmap.org) - Für die Geokodierung von Orten

**Hinweis:** Für eine vollständige Nutzung mit Echtzeit-Daten benötigen Sie API-Schlüssel für die verwendeten Dienste.
""")

# Zusätzliche Funktionen, die in einer vollständigen Implementierung hinzugefügt werden könnten:
# 1. Integration einer API für Wettervorhersagen für die nächsten Tage
# 2. Berücksichtigung von Mondphasen
# 3. Berücksichtigung von Höhenlage und Luftqualität
# 4. Integration von Informationen über astronomische Events (Meteorschauer, etc.)
